# Issue #140 Research Summary: Leaf-to-Spine Connection Generation

**Date**: 2026-01-05
**Issue**: Bug: leaf to spine connections are not being generated by generate device function
**Status**: Research Phase Complete

---

## Executive Summary

The HNP device generator currently **only creates server-to-switch connections**. Spine-leaf fabric connections are **explicitly documented as post-MVP** in `docs/DIET_QUICK_START.md`, but the topology calculation system computes spine quantities based on leaf uplink demand, creating an expectation gap.

**Key Finding**: This is a **functional gap**, not a bug per se, but represents incomplete implementation of the full topology planning vision.

---

## Research Questions Answered

### 1. Authoritative Rules for Leaf-Spine Wiring

**Source**: `HEDGEHOG_WIRING_REQUIREMENTS.md` (Section 1.3, 5.3)

**Topology Rules**:
- **Full-mesh requirement**: Each leaf MUST connect to every spine within same fabric
- **Unidirectional hierarchy**: Leaves cannot connect to other leaves; spines cannot connect to other spines
- **Fabric segregation**: Frontend, Backend, and OOB fabrics are independent

**Connection Format**:
- Connection CRD with type `fabric`
- Each link specifies: leaf.port, leaf.ip, spine.port, spine.ip
- IP addresses in /31 notation for point-to-point links

**Number of Links**:
- Default: 1 link per leaf-spine pair for full-mesh
- Determined by: `leaf.uplink_count ÷ spine.count` links per spine
- Example: 32 uplinks, 2 spines → 16 links to spine-1, 16 links to spine-2

---

### 2. Port Zone Mapping for Fabric Cabling

**Confirmed Mapping**:
- **Leaf uplinks**: Use `zone_type='uplink'`
- **Spine downlinks**: Use `zone_type='fabric'`

**Evidence**:
- DIET-112 commit (aee4742): Changed spine capacity lookup from UPLINK→FABRIC zones
- Rationale: "Spines are hierarchy top; they use FABRIC zones for leaf downlinks"

**Configuration Example** (from 128-GPU test case):
```python
# Leaf switch (fe-gpu-leaf)
SwitchPortZone(
    zone_name='server-ports',
    zone_type='server',
    port_spec='1-63:2',  # Odd ports for servers
    breakout_option='4x200g'
)
SwitchPortZone(
    zone_name='spine-uplinks',
    zone_type='uplink',
    port_spec='2-64:2',  # Even ports for uplinks
    breakout_option='1x800g'
)

# Spine switch (fe-spine)
SwitchPortZone(
    zone_name='leaf-downlinks',
    zone_type='fabric',
    port_spec='1-64',  # All ports for leaf connections
    breakout_option='1x800g'
)
```

**Fallback Rules**:
- If zones missing: Uses `uplink_ports_per_switch` override + total port count
- If both missing: Raises `ValidationError` (fail-fast design)

---

### 3. Breakout Behavior for Uplinks

**Function**: `determine_leaf_uplink_breakout()` in `topology_calculations.py:628-731`

**Algorithm**:
1. Calculate minimum breakout factor: `ceil(spine_count / physical_uplink_ports)`
2. Query supported breakout options from `BreakoutOption` model
3. Select smallest breakout where:
   - `logical_ports >= required_factor`
   - `logical_speed >= min_link_speed`
4. Return breakout or `None` if insufficient

**Examples**:
| Physical Ports | Spine Count | Required Breakout | Selected |
|----------------|-------------|-------------------|----------|
| 32 | 16 | 1x (32≥16) | 1x800G (no breakout) |
| 32 | 64 | 2x (32×2=64) | 2x400G |
| 32 | 128 | 4x (32×4=128) | 4x200G |
| 32 | 512 | 16x (not supported) | None (error) |

**Usage in Generation**:
- Currently: Only used for capacity calculations
- **Gap**: Not applied during cable/interface generation

---

### 4. MCLAG/Border-Leaf Nuances

#### MCLAG Pairs

**Model**: `PlanMCLAGDomain` in `topology_plans.py:491-545`

**Behavior**:
- When `PlanSwitchClass.mclag_pair=True`:
  - Calculated quantity rounded to nearest even number
  - Enforces paired deployment (2, 4, 6, ... switches)
- MCLAG domain specifies:
  - Peer link count & port range (switch-to-switch interconnect)
  - Session link count & port range (keepalive/management)

**Fabric Connection Behavior**:
- **Both switches in pair connect to all spines**
- Connection distribution: Alternating ports across pair
- Example: 64 uplinks, 2-switch MCLAG → 32 uplinks per switch

**Gap**: MCLAG peer/session links are **not generated** by device generator

#### Border-Leaf

**Status**: **Partially Implemented**

**What Exists**:
- `HedgehogRoleChoices.BORDER_LEAF` defined in `choices.py`
- Included in spine calculation as leaf equivalent (line 806, `topology_calculations.py`)

**What's Missing**:
- No special uplink/external port handling
- No validation of external connectivity requirements
- Spine's UPLINK zone intended for "border/external connections" (line 844 comment) but not implemented
- No test cases for border-leaf behavior

**Design Intent** (inferred):
- Border-leafs connect to spines like server-leafs
- Spines with UPLINK zones can connect to external/border networks
- Full implementation deferred (no timeline)

---

### 5. Naming & Determinism

#### Interface Naming

**Switch Interfaces**:
- Format: `E1/N` for native ports (e.g., E1/1, E1/64)
- Format: `E1/N/M` for breakout ports (e.g., E1/1/1, E1/1/2)
- Fixed by NetBox `InterfaceTemplate` on `DeviceType`

**Naming Rules**:
- Native (1x): Physical port number only
- 2x breakout: /1, /2
- 4x breakout: /1, /2, /3, /4
- 8x breakout: /1 through /8

**Server Interfaces**:
- Template-driven (issue #138): Use existing `InterfaceTemplate` names
- Legacy fallback: Generate from `nic_slot` with suffix stripping

#### Cable Metadata

**Custom Fields** (existing infrastructure):
```python
Device.custom_fields:
  - hedgehog_plan_id: str(plan.pk)
  - hedgehog_class: switch_class.switch_class_id
  - hedgehog_fabric: 'frontend'/'backend'/'oob'
  - hedgehog_role: 'spine'/'server-leaf'/'border-leaf'

Interface.custom_fields:
  - hedgehog_zone: 'server'/'uplink'/'fabric'
  - hedgehog_physical_port: int (e.g., 15)
  - hedgehog_breakout_index: int or None (e.g., 2 for /2)

Cable.custom_fields:
  - hedgehog_plan_id: str(plan.pk)
```

**Determinism**:
- Port allocation via `PortAllocatorV2` with sequential strategy
- Stable ordering: Devices sorted by name, ports sorted by zone priority
- Regeneration produces identical topology (if plan unchanged)

---

### 6. Source-of-Truth Documentation

**Foundation Issues** (GitHub):
- **#82**: Project Analysis & Architecture - Defines operational vs DIET tooling split
- **#83**: DIET PRD - Complete product requirements for topology planning
- **#84**: DIET Sprint Plan - Feature prioritization and MVP scope

**Specification Files**:
- `HEDGEHOG_WIRING_REQUIREMENTS.md` - Hedgehog fabric connection CRD specifications
- `HEDGEHOG_WIRING_RESEARCH_SUMMARY.md` - Analysis of Hedgehog fabric patterns
- `docs/DIET_QUICK_START.md` - User-facing quick start (MVP scope defined here)
- `docs/DIET_TEST_CASES.md` - Reference test case (128-GPU with spine sizing)

**Design Specs**:
- DIET-SPEC-003: Uplink Capacity from Zones (DIET-119 implementation)
- DIET-SPEC-004: Spine Switch Calculation (DIET-112 implementation)

**Key Commits**:
- `aee4742` - [DIET-112] Fix spine calculation to use FABRIC zones
- `2950257` - [DIET-119] Implement zone-based uplink capacity derivation
- `bcbca40` - [DIET-002] Zone-based speed derivation

---

## Current Implementation Status

### ✅ Fully Implemented

1. **Server-to-Switch Connections**
   - All distribution strategies (same-switch, alternating, rail-optimized)
   - Port allocation from SERVER zones
   - Interface template reuse (issue #138)
   - Cable generation with custom field metadata

2. **Switch Quantity Calculations**
   - Leaf sizing based on server port demand
   - Spine sizing based on leaf uplink demand
   - MCLAG pair enforcement (even counts)
   - Override quantity support

3. **Port Zone Infrastructure**
   - Zone types defined (SERVER, UPLINK, FABRIC, MCLAG, PEER, OOB)
   - Zone-based capacity derivation
   - Breakout selection algorithm
   - Port allocation with strategies (sequential, interleaved, custom)

4. **Data Models**
   - `PlanServerConnection` for server-to-switch connections
   - `PlanSwitchClass` with calculated/override quantities
   - `SwitchPortZone` for port segregation
   - `PlanMCLAGDomain` for MCLAG configuration

### ⚠️ Partially Implemented

1. **Uplink Port Zones**
   - Status: Defined and used in calculations
   - Gap: Not used during cable generation
   - Files affected: `device_generator.py` (no uplink allocation code)

2. **Fabric Port Zones**
   - Status: Spine capacity calculated from FABRIC zones
   - Gap: No cables created using these zones
   - Files affected: `device_generator.py` (no spine cabling)

3. **Border-Leaf Role**
   - Status: Role defined, included in calculations
   - Gap: No special uplink/external handling
   - Files affected: `topology_calculations.py` (recognized but not differentiated)

### ❌ Not Implemented

1. **Leaf-to-Spine Cable Generation**
   - No `_create_fabric_connections()` method
   - No uplink interface creation on leaf switches
   - No downlink interface creation on spine switches
   - No cables connecting leaves to spines

2. **MCLAG Peer/Session Links**
   - `PlanMCLAGDomain` model exists
   - Zone type `MCLAG` defined
   - **Gap**: No peer link cable generation

3. **Spine External Uplinks**
   - Spine UPLINK zone support designed (comment in code)
   - **Gap**: Not implemented or tested

4. **YAML Fabric Export**
   - Explicitly listed as post-MVP in `DIET_QUICK_START.md:517`
   - Connection CRD generation exists for server connections only

---

## Test Coverage Analysis

### Existing Tests

**Total Test Files**: 24 in `tests/test_topology_planning/`

**Coverage by Category**:
1. ✅ Server connection generation (test_generate_integration.py, test_device_generator.py)
2. ✅ Switch quantity calculations (test_topology_calculations.py - 60+ tests)
3. ✅ Uplink capacity derivation (test_uplink_capacity.py)
4. ✅ Port zone allocation (test_port_capacity.py, test_models_port_zones.py)
5. ✅ 128-GPU reference case (test_case_128gpu_command.py)
6. ✅ Unified generation/update workflow (test_unified_generate_update.py)

### Test Gaps

**No Tests For**:
1. ❌ Leaf-to-spine cable generation
2. ❌ Uplink interface creation
3. ❌ MCLAG peer link cabling
4. ❌ Fabric zone port allocation
5. ❌ Border-leaf special handling
6. ❌ Inter-switch connection validation

**Expected Counts** (from test_case_128gpu_command.py):
```python
# Current (servers only):
device_count = 164  # 128 servers + 36 switches
cable_count = 548   # Server-to-switch connections only

# With fabric connections (estimated):
# - 4 fe-leaves × 2 fe-spines × 32 uplinks/leaf = 256 fabric cables
# - 8 be-leaves × 4 be-spines × 32 uplinks/leaf = 1024 fabric cables
# Total: 548 + 256 + 1024 = 1828 cables
```

---

## Architecture Implications

### Extension Point

`DeviceGenerator._create_connections()` (lines 243-316) needs second phase:

```python
def _create_connections(self, switch_devices, server_devices):
    interfaces = []
    cables = []

    # Phase 1: Server-to-Switch (CURRENT)
    for server_class in self.plan.server_classes.all():
        for connection_def in server_class.connections.all():
            # ... existing server connection logic ...

    # Phase 2: Switch-to-Switch (NEW)
    fabric_interfaces, fabric_cables = self._create_fabric_connections(switch_devices)
    interfaces.extend(fabric_interfaces)
    cables.extend(fabric_cables)

    mclag_interfaces, mclag_cables = self._create_mclag_connections(switch_devices)
    interfaces.extend(mclag_interfaces)
    cables.extend(mclag_cables)

    return interfaces, cables
```

### Required New Methods

1. `_create_fabric_connections(switch_devices)`
   - For each fabric (frontend/backend/oob):
     - Get all leaves and spines in fabric
     - For each leaf:
       - Allocate uplink ports from UPLINK zones
       - For each spine:
         - Allocate downlink port from spine's FABRIC zone
         - Create Cable(leaf_interface, spine_interface)
   - Returns: interfaces, cables

2. `_create_mclag_connections(switch_devices)`
   - For each MCLAG domain:
     - Find paired switches (2 switches with matching switch_class)
     - Allocate peer link ports from MCLAG zone
     - Allocate session link ports from SESSION zone
     - Create cables between pairs
   - Returns: interfaces, cables

### Port Allocation Coordination

**Challenge**: Uplinks must be allocated **before** server ports to ensure capacity

**Current Flow** (sequential by connection):
```
server_connection_1 → allocate ports → create cables
server_connection_2 → allocate ports → create cables
...
```

**Proposed Flow** (by zone priority):
```
1. Allocate all UPLINK zone ports (reserve for fabric)
2. Allocate all MCLAG zone ports (reserve for peer links)
3. Allocate all SERVER zone ports (remaining capacity)
4. Generate all cables in order
```

**Implementation**:
- `PortAllocatorV2` already supports priority-based allocation
- No algorithm changes needed, only call order

---

## Open Design Decisions

### 1. Automatic vs Explicit Fabric Connections

**Option A: Derive Automatically** (Recommended)
- Pro: Aligns with calculation-driven design
- Pro: Full-mesh guaranteed
- Pro: No new UI/model needed
- Con: Less user control

**Option B: Explicit Model** (e.g., `PlanFabricConnection`)
- Pro: Explicit control
- Pro: Can model non-full-mesh topologies
- Con: Increases complexity
- Con: Requires UI, validation, recalculation logic

**Recommendation**: Option A for MVP, Option B for Phase 2 if needed

### 2. IP Address Assignment

**Options**:
1. Leave blank (defer to hhfab build step) - **RECOMMENDED FOR MVP**
2. Generate /31 point-to-point IPs (requires IP allocation model)
3. Allow user-specified IP ranges per fabric

**Hedgehog Requirement**: Connection CRDs include IPs in format `172.30.30.0/31`

**Recommendation**:
- NetBox device generation: Leave IPs blank
- YAML export (post-MVP): Generate IPs from configurable subnet ranges

### 3. Breakout Application

**Question**: When leaf uplink breakout is determined (e.g., 2x400G), should device generator:
1. Create interfaces with breakout suffix (E1/1/1, E1/1/2)
2. Rely on InterfaceTemplate with pre-defined breakout interfaces

**Current Behavior**:
- Server connections use template reuse (issue #138)
- No breakout interface generation for uplinks

**Recommendation**: Generate breakout interfaces dynamically for uplinks (no template exists)

### 4. YAML Export Scope

**Documented as Post-MVP**:
- Fabric connection CRDs
- MCLAG domain CRDs
- Switch/Server CRDs

**Question**: Should NetBox fabric cables be implemented separately from YAML export?

**Recommendation**: Yes - NetBox device generation provides value independently

---

## Risk Assessment

### Low Risk
- Extending `_create_connections()` with new phase (clean extension point)
- Reusing port allocation infrastructure (already zone-aware)
- Reusing cable generation patterns (established in server connections)

### Medium Risk
- Coordinating uplink allocation before server allocation (requires call order change)
- Ensuring MCLAG pair discovery (needs deterministic switch ordering)
- Breakout interface naming for dynamically generated interfaces

### High Risk
- Test coverage gaps (no existing tests for fabric connections)
- Regression risk (changes to `_create_connections()` affect all generation)
- Performance impact (1828 cables vs 548 in 128-GPU case - 3.3x increase)

### Mitigation Strategies
1. Implement behind feature flag for gradual rollout
2. Add comprehensive integration tests before implementation
3. Run performance benchmarks on large topologies (500+ devices)
4. Maintain backward compatibility (existing plans regenerate identically)

---

## Recommended Next Steps

### Phase 1: Specification & Architecture (1-2 days)
1. Review this research summary with stakeholders
2. Finalize design decisions (automatic vs explicit, IP assignment, etc.)
3. Create detailed technical specification
4. Design test plan (minimum 15-20 integration tests)

### Phase 2: Test-Driven Development (3-4 days)
1. Write integration tests for fabric connection generation
2. Write unit tests for new methods
3. Update existing tests to expect fabric cables
4. Implement to pass tests

### Phase 3: Implementation (3-4 days)
1. Implement `_create_fabric_connections()`
2. Implement `_create_mclag_connections()`
3. Update `_create_connections()` orchestration
4. Add validation & error handling

### Phase 4: Verification (1-2 days)
1. Run full test suite
2. Manual verification with 128-GPU case
3. Performance testing
4. Documentation updates

**Total Estimate**: 8-12 days for complete implementation

---

## Files Requiring Modification

### Core Implementation
- `netbox_hedgehog/services/device_generator.py` - Add fabric connection generation
- `netbox_hedgehog/services/port_allocator.py` - Verify priority-based allocation

### Tests (New)
- `netbox_hedgehog/tests/test_topology_planning/test_fabric_connections.py` (new file)
- `netbox_hedgehog/tests/test_topology_planning/test_mclag_connections.py` (new file)

### Tests (Updates)
- `test_generate_integration.py` - Update cable count expectations
- `test_case_128gpu_command.py` - Add fabric connection assertions
- `test_device_generator.py` - Add fabric connection unit tests

### Documentation
- `docs/DIET_QUICK_START.md` - Remove "post-MVP" note if implementing
- `docs/DIET_TEST_CASES.md` - Update expected counts

---

## Conclusion

Leaf-to-spine fabric connection generation is a **well-specified but unimplemented feature**. All required infrastructure exists (zone types, capacity calculations, port allocation), but the device generator only creates server connections. Implementation is straightforward with low technical risk but requires comprehensive test coverage to prevent regressions.

The primary blocker is not technical complexity but **project prioritization**: the feature was explicitly deferred as post-MVP. This research provides all information needed to implement when prioritized.
